{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de201b6b",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "f8c92c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from ast import literal_eval\n",
    "import json\n",
    "\n",
    "import torch\n",
    "\n",
    "from rouge_score import rouge_scorer\n",
    "from torchmetrics.text.bert import BERTScore\n",
    "# Note: Lines 188 and 196 of torchmetrics.bert were set to `truncation = True` as the previous code threw errors that failed to truncate text\n",
    "from nltk.translate import bleu_score\n",
    "\n",
    "from typing import List, Tuple, Union, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22046ed3",
   "metadata": {},
   "source": [
    "# Settings and Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf05896e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "# Mutes warning concerning tokenizers and forking processes\n",
    "%set_env TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79c7b47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RES_BASE      = '../../results/'\n",
    "\n",
    "BART_ZS_FP    = RES_BASE + 'bart_zshot_gens.csv'\n",
    "PRIMERA_ZS_FP = RES_BASE + 'primera_zshot_gens.csv'\n",
    "\n",
    "LR_RES_FP     = RES_BASE + 'lexrank_results.csv'\n",
    "CMOS_RES_FP   = RES_BASE + 'cmos_results.csv'\n",
    "TOGL_RES_FP   = RES_BASE + '/togl_decoding/togl_predictions.csv'\n",
    "COCO_RES_FP   = RES_BASE + 'cocosum_results.csv'\n",
    "BART_FS_FP    = RES_BASE + 'bart_fshot_gens.csv'\n",
    "PRIMERA_FS_FP = RES_BASE + 'primera_fshot_gens.csv'\n",
    "\n",
    "TOGL_ABL_FP   = RES_BASE + '/togl_decoding/togl_decoding_w_%d.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3fdb086",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer = True)\n",
    "\n",
    "bert_scorer = BERTScore(model_name_or_path = 'roberta-large', \n",
    "                        rescale_with_baseline = True, \n",
    "                        lang = 'en',\n",
    "                        verbose = True, \n",
    "                        max_length = 510,\n",
    "                        device = torch.device('cuda:0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5784704",
   "metadata": {},
   "source": [
    "# Data Reading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c4ae9709",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_zs_res = pd.read_csv(BART_ZS_FP)\n",
    "prim_zs_res = pd.read_csv(PRIMERA_ZS_FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ddd2635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extractive Baselines\n",
    "lr_res = pd.read_csv(LR_RES_FP)\n",
    "cmos_res = pd.read_csv(CMOS_RES_FP)\n",
    "\n",
    "# Abstractive Pre-trained Baselines\n",
    "bart_zs_res = pd.read_csv(BART_ZS_FP)\n",
    "bart_fs_res = pd.read_csv(BART_FS_FP)\n",
    "prim_zs_res = pd.read_csv(PRIMERA_ZS_FP)\n",
    "prim_fs_res = pd.read_csv(PRIMERA_FS_FP)\n",
    "\n",
    "# Abstract Contrastive Approaches\n",
    "coco_res = pd.read_csv(COCO_RES_FP)\n",
    "togl_res = pd.read_csv(TOGL_RES_FP)\n",
    "\n",
    "# Togl Weight Ablation\n",
    "togl_abl = []\n",
    "for i in range(2, 6):\n",
    "    togl_abl.append(pd.read_csv(TOGL_ABL_FP % i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a210316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_res['title_date'] = lr_res['title'] + '_' + lr_res['date']\n",
    "lr_res = lr_res[['title_date', 'lexrank_lsum', 'lexrank_rsum', 'left_sum', 'right_sum']]\n",
    "cmos_res['title_date'] = cmos_res['title'] + '_' + cmos_res['date']\n",
    "cmos_res = cmos_res[['title_date', 'cmos_lsum', 'cmos_rsum', 'left_sum', 'right_sum']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "311049b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "togl_res.columns = ['title_date', 'togl_lsum', 'togl_rsum']\n",
    "togl_res = togl_res.merge(lr_res[['title_date', 'left_sum', 'right_sum']], on = 'title_date')\n",
    "\n",
    "bart_fs_res = bart_fs_res.merge(lr_res[['title_date', 'left_sum', 'right_sum']], on = 'title_date')\n",
    "prim_fs_res = prim_fs_res.merge(lr_res[['title_date', 'left_sum', 'right_sum']], on = 'title_date')\n",
    "\n",
    "for i, togl_res_w in enumerate(togl_abl):\n",
    "    togl_abl[i].columns = ['title_date', 'togl_lsum', 'togl_rsum']\n",
    "    togl_abl[i] = togl_abl[i].merge(lr_res[['title_date', 'left_sum', 'right_sum']], on = 'title_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11da47ae",
   "metadata": {},
   "source": [
    "# Evaluation Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23941ea8",
   "metadata": {},
   "source": [
    "## Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "202b4cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rouge(text: str, ref: str) -> Tuple[float]:\n",
    "    '''\n",
    "        Get Rouge-F1 scores given a text and reference\n",
    "        \n",
    "        Parameters:\n",
    "            -text:str\n",
    "                Prediction text for rouge calculation\n",
    "            -ref: str\n",
    "                Reference summary for rouge calculation\n",
    "                \n",
    "        Return\n",
    "            Tuple of the ROUGE-1, ROUGE-2, and ROUGE-L scores\n",
    "    '''\n",
    "    \n",
    "    rouge = scorer.score(text, ref)\n",
    "    rouge1 = rouge['rouge1'].fmeasure\n",
    "    rouge2 = rouge['rouge2'].fmeasure\n",
    "    rougeL = rouge['rougeL'].fmeasure\n",
    "    \n",
    "    return rouge1, rouge2, rougeL\n",
    "\n",
    "def rouge_and_reverse(row: pd.Series, model: str, reverse = True) -> pd.Series:\n",
    "    '''\n",
    "        Calculate rouge scores given a row from a results dataset.\n",
    "        Also swap the left and right text for approaches that are not expected to distinguish\n",
    "            left and right perspectives.\n",
    "            \n",
    "        Parameters:\n",
    "            -row\n",
    "                Current row in the dataframe (to be used in apply/progress_apply)\n",
    "            -model: str\n",
    "                Name of the model to access predictions in the dataframe\n",
    "        Return:\n",
    "            Altered row including two columns with predictions that maximize ROUGE-2 (new_l_text, new_r_text)\n",
    "            as well as rouge F scores in separate columns in the form [lr]_rouge[12L]\n",
    "    '''\n",
    "    \n",
    "    lsum, rsum   = row[f'left_sum'], row['right_sum']\n",
    "    ltext, rtext = row[f'{model}_lsum'], row[f'{model}_rsum']\n",
    "    \n",
    "    # Rouge Scores\n",
    "    \n",
    "    # Calculate scores assuming predictions are aligned\n",
    "    lrouge_1f, lrouge_2f, lrouge_Lf = get_rouge(ltext, lsum)\n",
    "    rrouge_1f, rrouge_2f, rrouge_Lf = get_rouge(rtext, rsum)\n",
    "    \n",
    "    # Calculate scores with swapped left and right predictions\n",
    "    if reverse:\n",
    "        lrouge_1r, lrouge_2r, lrouge_Lr = get_rouge(ltext, rsum)\n",
    "        rrouge_1r, rrouge_2r, rrouge_Lr = get_rouge(rtext, lsum)\n",
    "    \n",
    "    # Instantiate the left and right rouge scores before possibly reversing scores\n",
    "    lrouge_1, lrouge_2, lrouge_L = lrouge_1f, lrouge_2f, lrouge_Lf\n",
    "    rrouge_1, rrouge_2, rrouge_L = rrouge_1f, rrouge_2f, rrouge_Lf\n",
    "    \n",
    "    # If the reverse scoring is better than the forward scoring, swap left and right texts\n",
    "    if ((lrouge_2f + rrouge_2f) < (lrouge_2r + rrouge_2r)) and reverse:\n",
    "        # Swap left and right text\n",
    "        temp = ltext\n",
    "        ltext = rtext\n",
    "        rtext = temp\n",
    "        \n",
    "        lrouge_1, lrouge_2, lrouge_L = lrouge_1r, lrouge_2r, lrouge_Lr\n",
    "        rrouge_1, rrouge_2, rrouge_L = rrouge_1r, rrouge_2r, rrouge_Lr\n",
    "            \n",
    "    row['new_l_text'] = ltext\n",
    "    row['new_r_text'] = rtext\n",
    "    row['l_rouge1'] = lrouge_1\n",
    "    row['l_rouge2'] = lrouge_2\n",
    "    row['l_rougeL'] = lrouge_L\n",
    "    row['r_rouge1'] = rrouge_1\n",
    "    row['r_rouge2'] = rrouge_2\n",
    "    row['r_rougeL'] = rrouge_L\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "58c8801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_self_bleus(preds1: List[str], preds2: List[str]) -> List[float]:\n",
    "    '''\n",
    "        Calculates self-bleu scores for lists of left and right predictions\n",
    "        \n",
    "        Parameters:\n",
    "            -preds1: List[str]\n",
    "                List of left (or right) predicted summaries\n",
    "            -preds2: List[str]\n",
    "                List of right (or left) predicted summaries\n",
    "        \n",
    "        Return:\n",
    "            -List of self-BLEU scores for each pair of texts\n",
    "    '''\n",
    "    \n",
    "    # Iterate over predicted pairs and calculate self-bleu scores\n",
    "    self_bleus = []\n",
    "    for pred1, pred2 in tqdm(zip(preds1, preds2)):\n",
    "        bleu = bleu_score.sentence_bleu(pred1, pred2, weights = (1.0,))\n",
    "        self_bleus.append(bleu)\n",
    "        \n",
    "    return self_bleus\n",
    "\n",
    "def get_self_bleus_df(df: pd.DataFrame, model: str) -> List[float]:\n",
    "    '''\n",
    "        Calculate the self-BLEU scores given a dataframe with predictions\n",
    "        \n",
    "        Parameters:\n",
    "            -df: pd.DataFrame\n",
    "                Dataframe containing at least the model predictions with columns named ('<MODEL>_lsum', '<MODEL>_rsum')\n",
    "            -model: str\n",
    "                Name of the model responsible for predictions\n",
    "                \n",
    "        Return:\n",
    "            List of self-BLEU scores for each pair of texts\n",
    "    '''\n",
    "    \n",
    "    ltexts = df[f'{model}_lsum'].values\n",
    "    rtexts = df[f'{model}_rsum'].values\n",
    "    \n",
    "    self_bleus = get_self_bleus(ltexts, rtexts)\n",
    "    \n",
    "    return self_bleus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "570f253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_scores_df(df:pd.DataFrame, model:str) -> pd.DataFrame:\n",
    "    '''\n",
    "        Calculate bert scores given a dataframe with model predictions and summaries. Should run rouge_and_reverse\n",
    "            first to ensure summaries and predictions are aligned\n",
    "            \n",
    "        Parameters:\n",
    "            -df: pd.DataFrame\n",
    "                Dataframe with predicted summaries (new_[lr]_text) and reference summaries ([left|right]_sum)\n",
    "            -model: str\n",
    "                Name of model responsible for predictions\n",
    "        \n",
    "        Return:\n",
    "            Original dataframe with additional columns 'l_bscore' and 'r_bscore' holding BERTScores\n",
    "    '''\n",
    "    \n",
    "    l_bscores = bert_scorer(df['new_l_text'].astype(str).tolist(), df['left_sum'].astype(str).tolist())\n",
    "    r_bscores = bert_scorer(df['new_r_text'].astype(str).tolist(), df['right_sum'].astype(str).tolist())\n",
    "    \n",
    "    df['l_bscore'] = l_bscores['f1']\n",
    "    df['r_bscore'] = r_bscores['f1']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a358fbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_metrics(df: pd.DataFrame):\n",
    "    '''\n",
    "        Calculate average coverage and diversity metrics for a dataframe with row-level metrics\n",
    "        \n",
    "        Parameters:\n",
    "            -df: pd.Dataframe\n",
    "                Dataframe holding ROUGE scores, self-BLEU, and BERTScores after running above functions\n",
    "        \n",
    "        Return:\n",
    "            Dictionary holding average metrics across ROUGE, self-BLEU, and BERTScores\n",
    "    '''\n",
    "    \n",
    "    l_rouge1 = df['l_rouge1'].mean()\n",
    "    l_rouge2 = df['l_rouge2'].mean()\n",
    "    l_rougeL = df['l_rougeL'].mean()\n",
    "    l_bscore = df['l_bscore'].mean()\n",
    "    \n",
    "    r_rouge1 = df['r_rouge1'].mean()\n",
    "    r_rouge2 = df['r_rouge2'].mean()\n",
    "    r_rougeL = df['r_rougeL'].mean()\n",
    "    r_bscore = df['r_bscore'].mean()\n",
    "    \n",
    "    self_bleu = df['self_bleu'].mean()\n",
    "    \n",
    "    return {'l_rouge1': l_rouge1, \n",
    "            'l_rouge2': l_rouge2, \n",
    "            'l_rougeL': l_rougeL,\n",
    "            'l_bscore': l_bscore,\n",
    "            'r_rouge1': r_rouge1, \n",
    "            'r_rouge2': r_rouge2, \n",
    "            'r_rougeL': r_rougeL,\n",
    "            'r_bscore': r_bscore,\n",
    "            'self_bleu': self_bleu}\n",
    "\n",
    "def print_metrics(metric_dict: dict):\n",
    "    '''\n",
    "        Prints average metrics for dictionary returned by get_avg_metrics\n",
    "        \n",
    "        Parameters:\n",
    "            -metric_dict\n",
    "                Dictionary holding average metrics\n",
    "        \n",
    "        Return: None\n",
    "    '''\n",
    "    \n",
    "    for metric, val in metric_dict.items():\n",
    "        print(f'     {metric:10s}: {val * 100.:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5dbd4d",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7ff496",
   "metadata": {},
   "source": [
    "##  Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "280744da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge lr_res to bart and primera predictions to get reference summaries\n",
    "bart_zs_res = bart_zs_res.merge(lr_res[['title_date', 'left_sum', 'right_sum']], on = 'title_date')\n",
    "prim_zs_res = prim_zs_res.merge(lr_res[['title_date', 'left_sum', 'right_sum']], on = 'title_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ce3618b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy prediction columns to left and right so that the same evaluation functions can be used\n",
    "# Duplicated because the zero shot setting only outputs single predictions\n",
    "bart_zs_res['bart_lsum'] = bart_zs_res['bart_sum']\n",
    "bart_zs_res = bart_zs_res.rename({'bart_sum': 'bart_rsum'}, axis = 1)\n",
    "\n",
    "prim_zs_res['primera_lsum'] = prim_zs_res['primera_sum']\n",
    "prim_zs_res = prim_zs_res.rename({'primera_sum': 'primera_rsum'}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c70a05cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 735/735 [00:07<00:00, 93.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# Rouge scores for zero-shot setting\n",
    "bart_zs_res = bart_zs_res.progress_apply(lambda row: rouge_and_reverse(row, 'bart'), axis = 1)\n",
    "prim_zs_res = prim_zs_res.progress_apply(lambda row: rouge_and_reverse(row, 'primera'), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "797e2786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "735it [00:00, 746.79it/s]\n",
      "735it [00:09, 81.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# Self-BLEU scores for zero-shot setting\n",
    "bart_zs_res['self_bleu'] = get_self_bleus_df(bart_zs_res, 'bart')\n",
    "prim_zs_res['self_bleu'] = get_self_bleus_df(prim_zs_res, 'primera')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "af1fb55f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34295a1b2da84a67906fd34def7b94b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e46be670881e4da486bd525f86899a72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e4cec89fb95482da4a258ba01c89350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669510d25107477e8221b59496394816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79fe02ee9048445c97de02b019a07cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed57477a77bb4214aa7ffe8df29639ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39822e9cfbb147feb1302dd6c0cdfd0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad623f8d799e4f61956238407e6f435a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# BERTScores for zero-shot setting\n",
    "bart_zs_res = get_bert_scores_df(bart_zs_res, 'bart')\n",
    "prim_zs_res = get_bert_scores_df(prim_zs_res, 'primera')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a5e40328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average scores across predictions\n",
    "bart_stat = get_avg_metrics(bart_zs_res)\n",
    "prim_stat = get_avg_metrics(prim_zs_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ded2f0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---BART---\n",
      "     l_rouge1  : 17.61\n",
      "     l_rouge2  : 1.29\n",
      "     l_rougeL  : 13.48\n",
      "     l_bscore  : 2.58\n",
      "     r_rouge1  : 17.50\n",
      "     r_rouge2  : 1.35\n",
      "     r_rougeL  : 13.54\n",
      "     r_bscore  : 2.53\n",
      "     self_bleu : 29.11\n",
      "---PRIMERA---\n",
      "     l_rouge1  : 11.12\n",
      "     l_rouge2  : 1.28\n",
      "     l_rougeL  : 8.27\n",
      "     l_bscore  : -18.10\n",
      "     r_rouge1  : 11.23\n",
      "     r_rouge2  : 1.24\n",
      "     r_rougeL  : 8.29\n",
      "     r_bscore  : -18.46\n",
      "     self_bleu : 7.31\n"
     ]
    }
   ],
   "source": [
    "print('---BART---')\n",
    "print_metrics(bart_stat)\n",
    "print('---PRIMERA---')\n",
    "print_metrics(prim_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb3aace",
   "metadata": {},
   "source": [
    "## Experiment 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13fca02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 735/735 [00:03<00:00, 186.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 735/735 [00:03<00:00, 233.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 735/735 [00:03<00:00, 229.99it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 735/735 [00:08<00:00, 87.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 735/735 [00:03<00:00, 226.31it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 735/735 [00:04<00:00, 181.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# Calculate ROUGE Scores and reverse predictions if needed for baselines and ToGL-Decoding\n",
    "lr_res      = lr_res.progress_apply(lambda row: rouge_and_reverse(row, 'lexrank'), axis = 1)\n",
    "cmos_res    = cmos_res.progress_apply(lambda row: rouge_and_reverse(row, 'cmos'), axis = 1)\n",
    "\n",
    "bart_fs_res = bart_fs_res.progress_apply(lambda row: rouge_and_reverse(row, 'bart'), axis = 1)\n",
    "prim_fs_res = prim_fs_res.progress_apply(lambda row: rouge_and_reverse(row, 'primera'), axis = 1)\n",
    "\n",
    "togl_res    = togl_res.progress_apply(lambda row: rouge_and_reverse(row, 'togl'), axis = 1)\n",
    "coco_res    = coco_res.progress_apply(lambda row: rouge_and_reverse(row, 'coco'), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5eaad792",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "735it [00:02, 328.85it/s]\n",
      "735it [00:00, 1131.26it/s]\n",
      "735it [00:00, 845.36it/s]\n",
      "735it [00:09, 74.57it/s]\n",
      "735it [00:00, 744.26it/s]\n",
      "735it [00:02, 345.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# Calculate Self-BLEU Scores\n",
    "lr_res['self_bleu']      = get_self_bleus_df(lr_res, 'lexrank')\n",
    "cmos_res['self_bleu']    = get_self_bleus_df(cmos_res, 'cmos')\n",
    "\n",
    "bart_fs_res['self_bleu'] = get_self_bleus_df(bart_fs_res, 'bart')\n",
    "prim_fs_res['self_bleu'] = get_self_bleus_df(prim_fs_res, 'primera')\n",
    "\n",
    "togl_res['self_bleu']    = get_self_bleus_df(togl_res, 'togl')\n",
    "coco_res['self_bleu']    = get_self_bleus_df(coco_res, 'coco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f658caac",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a8e788534145d2bf22daf096c675e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7209c9c9da449e7917f3d2281677155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d052e1d1cf4c5886bf2f3b98594a3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcecd0bb2ea84872860c95fb154a8c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f6b8981c310>\n",
      "Exception ignored in: Traceback (most recent call last):\n",
      "  File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f6b8981c310>    <function _MultiProcessingDataLoaderIter.__del__ at 0x7f6b8981c310>\n",
      "self._shutdown_workers()\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
      "  File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
      "  File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
      "        if w.is_alive():    self._shutdown_workers()\n",
      "self._shutdown_workers()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
      "      File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      "    AssertionErrorif w.is_alive():if w.is_alive():\n",
      ": \n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "can only test a child process        \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "AssertionErrorAssertionError: : can only test a child processcan only test a child process\n",
      "\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f6b8981c310>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68bd401cb682400b972d470cdbff40bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e9daef0ea64d0aa97d8808836c40ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf303fc630c4b588eba8710b83de97f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe29861650f745c0a395e8f3fc43c901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6154262b245c4ff6a340ea5c5a0b8d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c232f1c93aec4eff90e4bd09eba6597d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca431df657642c3b653721696599d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b9e1ccf30d4bd3a290bf7fcf27228e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "addfe862e5014ff9a5631ae84252ddc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b42e41e1ecb4a23b09e13edfc2fdd07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d882c5c433f04c84b2acea891459e3bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b880f87183d449c8bf3b64c3ba1e34fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f6b8981c310>Exception ignored in: \n",
      "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f6b8981c310>Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f6b8981c310>  File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f6b8981c310>  File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
      "  File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
      "    \n",
      "self._shutdown_workers()Traceback (most recent call last):\n",
      "        \n",
      "  File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
      "self._shutdown_workers()self._shutdown_workers()  File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
      "\n",
      "\n",
      "  File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
      "      File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
      "    self._shutdown_workers()if w.is_alive():        \n",
      "\n",
      "if w.is_alive():if w.is_alive():  File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "\n",
      "      File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'        \n",
      "if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'AssertionError\n",
      "\n",
      "\n",
      ": AssertionError  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "AssertionErrorcan only test a child process: :     \n",
      "can only test a child processcan only test a child processassert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "\n",
      "AssertionError: can only test a child process\n",
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf31af2504c4428ac35d72edd5443b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c583ed1790b14cb3affb0acbf36efdc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095b4fdf333d4b71b744300e46ed810e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec82645c19944f0a810403b37debc142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37857ded5bf64dbd8bb96726f76285f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89714b0b349f47c580d76e42653e122e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b8cc9c71dfb497a932c2c82c9ae6aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd488dcf9cc4a15a4fbc81445310836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate BERT Scores\n",
    "lr_res_ = get_bert_scores_df(lr_res, 'lexrank')\n",
    "cmos_res_ = get_bert_scores_df(cmos_res, 'cmos')\n",
    "coco_res_ = get_bert_scores_df(coco_res, 'coco')\n",
    "togl_res_ = get_bert_scores_df(togl_res, 'togl')\n",
    "bart_fs_res_ = get_bert_scores_df(bart_fs_res, 'bart')\n",
    "prim_fs_res_ = get_bert_scores_df(prim_fs_res, 'primera')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34baa872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average metrics and prepare for DataFrame display\n",
    "lr_stat   = get_avg_metrics(lr_res)\n",
    "cmos_stat = get_avg_metrics(cmos_res)\n",
    "bart_stat = get_avg_metrics(bart_fs_res)\n",
    "prim_stat = get_avg_metrics(prim_fs_res)\n",
    "coco_stat = get_avg_metrics(coco_res)\n",
    "togl_stat = get_avg_metrics(togl_res)\n",
    "\n",
    "lr_stat['model']   = 'LexRank'\n",
    "cmos_stat['model'] = 'CMOS'\n",
    "bart_stat['model'] = 'BART'\n",
    "prim_stat['model'] = 'PRIMERA'\n",
    "coco_stat['model'] = 'CoCoSum'\n",
    "togl_stat['model'] = 'ToGL-Decoding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4102b21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate performance metrics across model for easy display\n",
    "all_stat = pd.DataFrame([lr_stat, cmos_stat, bart_stat, prim_stat, coco_stat, togl_stat])\n",
    "all_stat = all_stat[['model'] + list(all_stat.columns)[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "02528a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>l_rouge1</th>\n",
       "      <th>l_rouge2</th>\n",
       "      <th>l_rougeL</th>\n",
       "      <th>l_bscore</th>\n",
       "      <th>r_rouge1</th>\n",
       "      <th>r_rouge2</th>\n",
       "      <th>r_rougeL</th>\n",
       "      <th>r_bscore</th>\n",
       "      <th>self_bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LexRank</td>\n",
       "      <td>0.096816</td>\n",
       "      <td>0.008024</td>\n",
       "      <td>0.076513</td>\n",
       "      <td>-0.184348</td>\n",
       "      <td>0.135319</td>\n",
       "      <td>0.017496</td>\n",
       "      <td>0.103736</td>\n",
       "      <td>-0.172808</td>\n",
       "      <td>0.126337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CMOS</td>\n",
       "      <td>0.126254</td>\n",
       "      <td>0.018229</td>\n",
       "      <td>0.105159</td>\n",
       "      <td>0.010428</td>\n",
       "      <td>0.122510</td>\n",
       "      <td>0.015087</td>\n",
       "      <td>0.101993</td>\n",
       "      <td>0.010075</td>\n",
       "      <td>0.261325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BART</td>\n",
       "      <td>0.181609</td>\n",
       "      <td>0.014011</td>\n",
       "      <td>0.140382</td>\n",
       "      <td>0.036343</td>\n",
       "      <td>0.187096</td>\n",
       "      <td>0.015722</td>\n",
       "      <td>0.145058</td>\n",
       "      <td>0.038252</td>\n",
       "      <td>0.276103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRIMERA</td>\n",
       "      <td>0.106487</td>\n",
       "      <td>0.014488</td>\n",
       "      <td>0.079086</td>\n",
       "      <td>-0.202654</td>\n",
       "      <td>0.109478</td>\n",
       "      <td>0.014274</td>\n",
       "      <td>0.080863</td>\n",
       "      <td>-0.203080</td>\n",
       "      <td>0.061918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CoCoSum</td>\n",
       "      <td>0.170468</td>\n",
       "      <td>0.022529</td>\n",
       "      <td>0.132281</td>\n",
       "      <td>-0.010275</td>\n",
       "      <td>0.165706</td>\n",
       "      <td>0.019860</td>\n",
       "      <td>0.130348</td>\n",
       "      <td>-0.008377</td>\n",
       "      <td>0.151335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ToGL-Decoding</td>\n",
       "      <td>0.177729</td>\n",
       "      <td>0.012607</td>\n",
       "      <td>0.141611</td>\n",
       "      <td>0.029455</td>\n",
       "      <td>0.177537</td>\n",
       "      <td>0.012226</td>\n",
       "      <td>0.141667</td>\n",
       "      <td>0.025904</td>\n",
       "      <td>0.272091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  l_rouge1  l_rouge2  l_rougeL  l_bscore  r_rouge1  r_rouge2  \\\n",
       "0        LexRank  0.096816  0.008024  0.076513 -0.184348  0.135319  0.017496   \n",
       "1           CMOS  0.126254  0.018229  0.105159  0.010428  0.122510  0.015087   \n",
       "2           BART  0.181609  0.014011  0.140382  0.036343  0.187096  0.015722   \n",
       "3        PRIMERA  0.106487  0.014488  0.079086 -0.202654  0.109478  0.014274   \n",
       "4        CoCoSum  0.170468  0.022529  0.132281 -0.010275  0.165706  0.019860   \n",
       "5  ToGL-Decoding  0.177729  0.012607  0.141611  0.029455  0.177537  0.012226   \n",
       "\n",
       "   r_rougeL  r_bscore  self_bleu  \n",
       "0  0.103736 -0.172808   0.126337  \n",
       "1  0.101993  0.010075   0.261325  \n",
       "2  0.145058  0.038252   0.276103  \n",
       "3  0.080863 -0.203080   0.061918  \n",
       "4  0.130348 -0.008377   0.151335  \n",
       "5  0.141667  0.025904   0.272091  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013332c6",
   "metadata": {},
   "source": [
    "# Experiment 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca60f092",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 735/735 [00:03<00:00, 225.79it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 735/735 [00:03<00:00, 227.09it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 735/735 [00:03<00:00, 217.60it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 735/735 [00:03<00:00, 225.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Rouge Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "735it [00:00, 738.01it/s]\n",
      "735it [00:00, 738.06it/s]\n",
      "735it [00:01, 715.36it/s]\n",
      "735it [00:01, 610.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Self-Bleu Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5905a9cd9800440ea1757769dc7988ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fcb6dc2678041ce923712028805a96c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c4fda27f6cf4848931b3d5e0575abef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1411daa4bf94492ba470d037639879a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f29dd33f280>Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f29dd33f280>Traceback (most recent call last):\n",
      "Exception ignored in: \n",
      "  File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f29dd33f280>Traceback (most recent call last):\n",
      "  File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
      "\n",
      "    Traceback (most recent call last):\n",
      "    self._shutdown_workers()  File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
      "self._shutdown_workers()\n",
      "\n",
      "  File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
      "  File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
      "        self._shutdown_workers()    if w.is_alive():\n",
      "\n",
      "if w.is_alive():  File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "      File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'    if w.is_alive():\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      ": AssertionErrorcan only test a child process:     \n",
      "can only test a child processassert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f29dd33f280>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc09d360253b4a85b479ddb791b9d995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36511920d36b4f7e812ffd7d796976d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f0443ade9941969780f802d3e365dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66bffff6bdee4b498bbe07ea8f8df537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4175199083f4685afd9c0a8264e46a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d18fab30b2164020a85a0e2a76810db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "383c167dbcea47df93daf6b83a1c0eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe122ba3a29d427d98a3f78a9d6ba615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0920a5be659d4fafa1986a90e1d9540a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1072ada409224a739fb32d7486ae0df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e81c4f561744369447efde9066f1b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7c256882514806a1dbc5c65f3faa98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f29dd33f280><function _MultiProcessingDataLoaderIter.__del__ at 0x7f29dd33f280>Exception ignored in: \n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f29dd33f280>Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
      "  File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
      "            self._shutdown_workers()self._shutdown_workers()self._shutdown_workers()\n",
      "\n",
      "\n",
      "  File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
      "  File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
      "  File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
      "            if w.is_alive():if w.is_alive():\n",
      "if w.is_alive():\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "          File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      "\n",
      "AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process': AssertionError\n",
      "can only test a child process: AssertionError\n",
      "can only test a child process: \n",
      "can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f29dd33f280>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ndeas/envs/test_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Bert Score Evaluation\n"
     ]
    }
   ],
   "source": [
    "# Calculate all metrics for each value of sigma tested\n",
    "for i, togl_res_w in enumerate(togl_abl):\n",
    "    togl_abl[i] = togl_res_w.progress_apply(lambda row: rouge_and_reverse(row, 'togl'), axis = 1)\n",
    "print('Completed Rouge Evaluation')\n",
    "\n",
    "for i, togl_res_w in enumerate(togl_abl):\n",
    "    togl_abl[i]['self_bleu'] = get_self_bleus_df(togl_abl[i], 'togl')\n",
    "print('Completed Self-Bleu Evaluation')\n",
    "    \n",
    "for i, togl_res_w in enumerate(togl_abl):\n",
    "    togl_abl[i] = get_bert_scores_df(togl_abl[i], 'lexrank')\n",
    "print('Completed Bert Score Evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "000f9c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate metrics for each sigma value and prepare for Dataframe display\n",
    "togl_abl_stat = []\n",
    "for i, togl_res_w in enumerate(togl_abl):\n",
    "    togl_abl_stat.append(get_avg_metrics(togl_res_w))\n",
    "    togl_abl_stat[i]['togl_weight'] = (i + 2) / 10.\n",
    "\n",
    "togl_abl_stat = pd.DataFrame(togl_abl_stat)\n",
    "togl_abl_stat = togl_abl_stat[['togl_weight'] + list(togl_abl_stat.columns)[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3fc2eb10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>togl_weight</th>\n",
       "      <th>l_rouge1</th>\n",
       "      <th>l_rouge2</th>\n",
       "      <th>l_rougeL</th>\n",
       "      <th>l_bscore</th>\n",
       "      <th>r_rouge1</th>\n",
       "      <th>r_rouge2</th>\n",
       "      <th>r_rougeL</th>\n",
       "      <th>r_bscore</th>\n",
       "      <th>self_bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.177385</td>\n",
       "      <td>0.013694</td>\n",
       "      <td>0.142372</td>\n",
       "      <td>0.034799</td>\n",
       "      <td>0.179667</td>\n",
       "      <td>0.012961</td>\n",
       "      <td>0.142940</td>\n",
       "      <td>0.034284</td>\n",
       "      <td>0.260219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.167495</td>\n",
       "      <td>0.014120</td>\n",
       "      <td>0.134879</td>\n",
       "      <td>0.058693</td>\n",
       "      <td>0.173620</td>\n",
       "      <td>0.014497</td>\n",
       "      <td>0.139440</td>\n",
       "      <td>0.050904</td>\n",
       "      <td>0.234360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.143871</td>\n",
       "      <td>0.011253</td>\n",
       "      <td>0.120499</td>\n",
       "      <td>0.100386</td>\n",
       "      <td>0.152655</td>\n",
       "      <td>0.013568</td>\n",
       "      <td>0.124562</td>\n",
       "      <td>0.084721</td>\n",
       "      <td>0.211600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.126727</td>\n",
       "      <td>0.008733</td>\n",
       "      <td>0.105333</td>\n",
       "      <td>0.119465</td>\n",
       "      <td>0.132356</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.110143</td>\n",
       "      <td>0.119975</td>\n",
       "      <td>0.178446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   togl_weight  l_rouge1  l_rouge2  l_rougeL  l_bscore  r_rouge1  r_rouge2  \\\n",
       "0          0.2  0.177385  0.013694  0.142372  0.034799  0.179667  0.012961   \n",
       "1          0.3  0.167495  0.014120  0.134879  0.058693  0.173620  0.014497   \n",
       "2          0.4  0.143871  0.011253  0.120499  0.100386  0.152655  0.013568   \n",
       "3          0.5  0.126727  0.008733  0.105333  0.119465  0.132356  0.010500   \n",
       "\n",
       "   r_rougeL  r_bscore  self_bleu  \n",
       "0  0.142940  0.034284   0.260219  \n",
       "1  0.139440  0.050904   0.234360  \n",
       "2  0.124562  0.084721   0.211600  \n",
       "3  0.110143  0.119975   0.178446  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "togl_abl_stat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
