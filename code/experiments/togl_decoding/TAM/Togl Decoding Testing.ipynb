{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a63e1ff2-7b41-413e-8647-0ca759b59e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from transformers import BartTokenizer\n",
    "from transformers import BartForConditionalGeneration\n",
    "from transformers.modeling_utils import PreTrainedModel\n",
    "from transformers.generation_utils import top_k_top_p_filtering, BeamSearchScorer\n",
    "from transformers.pytorch_utils import torch_int_div\n",
    "\n",
    "\n",
    "import data_utils, dataset, model_utils, topic_metrics\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f329f1d-b54c-44a1-a3be-76d267f5d974",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751ff5bb-9367-465c-b236-31bc8fcc9169",
   "metadata": {},
   "source": [
    "# Loading Tokenizers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "793778a3-18c5-4e69-8bac-b0207de77b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bec26f6f-bed2-4071-a73c-e76588152bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ec719b-e5b0-4c8f-a0fe-68335c85ce8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Custom Decoding Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "367edfd6-8ce3-4fe3-bb11-8132e8b70c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToGLDecoder:\n",
    "    \n",
    "    def __init__(self,\n",
    "                model: PreTrainedModel,\n",
    "                tokenizer,\n",
    "                top_p: float = 1.0,\n",
    "                togl_func: str = 'sum',\n",
    "                togl_func_kwargs: dict = None,\n",
    "                device = None):\n",
    "        '''\n",
    "            Parameters:\n",
    "                -model: PreTrainedModel\n",
    "                    A Huggingface pretrained model capable of generating text\n",
    "                -top_p: float\n",
    "                    Parameter for top-p sampling decoding method\n",
    "                -togl_func\n",
    "                    Function used to combine model predictions and topic model word distribution.\n",
    "                    Defaults to the sum of the generation and topic model word distributions with weight 1.\n",
    "                -togl_func_kwargs\n",
    "                    Keyword arguments to pass to the togl_func beyond word distribution parameters\n",
    "                -device\n",
    "                    Torch/Cuda device to use while generating\n",
    "        '''\n",
    "        \n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab_size = self.model.lm_head.out_features\n",
    "        \n",
    "        self.top_p = top_p\n",
    "        if type(togl_func) == str:\n",
    "            assert togl_func in ('sum'), f'togl_func {togl_func} has not been implemented'\n",
    "            if togl_func == 'sum':\n",
    "                self.togl_func = self.togl_sum\n",
    "        else:\n",
    "            self.togl_func = togl_func\n",
    "        \n",
    "        self.togl_func_kwargs = togl_func_kwargs\n",
    "        \n",
    "        self.device = device if device else torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def generate(self,\n",
    "                    inputs: torch.Tensor,\n",
    "                    togl_tuple: tuple,\n",
    "                    togl_start: int = 2,\n",
    "                    togl_weight: int = 0.1,\n",
    "                    use_cache: bool = True,\n",
    "                    decoder_start_token_id = None,\n",
    "                    num_beams: int  = 3,\n",
    "                    no_repeat_ngram_size = 3,\n",
    "                    min_length: int = 16,\n",
    "                    max_length: int = 1024,\n",
    "                    early_stopping: bool = True,\n",
    "                    **model_kwargs):\n",
    "        '''\n",
    "            Generates a sequence using beam search sampling incorporating ToGL-Decoding.\n",
    "            \n",
    "            Code drawn from \n",
    "                - https://github.com/huggingface/transformers/blob/v4.25.1/src/transformers/generation/utils.py#L998\n",
    "                    - beam_sample function\n",
    "                - https://github.com/megagonlabs/cocosum/blob/main/decode.py\n",
    "                    - generate_function\n",
    "        '''\n",
    "        \n",
    "        batch_size = 1\n",
    "        \n",
    "        inputs           = inputs.to(self.device)\n",
    "        \n",
    "        togl_probs       = self.togl_convert(togl_tuple, togl_weight)\n",
    "        togl_probs       = togl_probs.to(self.device)\n",
    "            \n",
    "        inputs_t, model_input_name, model_kwargs = self.model._prepare_model_inputs(inputs, self.tokenizer.bos_token_id, model_kwargs)\n",
    "        \n",
    "        model_kwargs = self.model._prepare_encoder_decoder_kwargs_for_generation(\n",
    "            inputs_t, model_kwargs, model_input_name\n",
    "        )\n",
    "        \n",
    "        input_ids = self.model._prepare_decoder_input_ids_for_generation(\n",
    "                batch_size,\n",
    "                decoder_start_token_id=self.tokenizer.bos_token_id,\n",
    "                bos_token_id=self.tokenizer.bos_token_id,\n",
    "                model_kwargs=model_kwargs,\n",
    "                device=self.device,\n",
    "            )\n",
    "        \n",
    "        logits_processor = self.model.model._get_logits_processor(\n",
    "            repetition_penalty = None,\n",
    "            no_repeat_ngram_size = no_repeat_ngram_size,\n",
    "            encoder_no_repeat_ngram_size=None,\n",
    "            input_ids_seq_length = input_ids.shape[-1],\n",
    "            encoder_input_ids = inputs_t,\n",
    "            min_length=min_length,\n",
    "            max_length=max_length,\n",
    "            eos_token_id=self.tokenizer.eos_token_id,\n",
    "            forced_bos_token_id=None,\n",
    "            forced_eos_token_id=None,\n",
    "            num_beams=num_beams,\n",
    "            num_beam_groups=None,\n",
    "            diversity_penalty=None,\n",
    "            remove_invalid_values=None,\n",
    "            bad_words_ids = None,\n",
    "            prefix_allowed_tokens_fn = None,\n",
    "            exponential_decay_length_penalty = None,\n",
    "            logits_processor = [],\n",
    "            renormalize_logits = None,\n",
    "        )\n",
    "        \n",
    "        \n",
    "        stopping_criteria = self.model.model._get_stopping_criteria(\n",
    "            max_length = max_length, max_time = None, stopping_criteria = []\n",
    "        )\n",
    "        \n",
    "        # Setup beam scorer for searching generations\n",
    "        beam_scorer = BeamSearchScorer(\n",
    "            batch_size = batch_size,\n",
    "            num_beams = num_beams,\n",
    "            device = self.device,\n",
    "            do_early_stopping = early_stopping,\n",
    "            num_beam_hyps_to_keep = 1\n",
    "        )\n",
    "        \n",
    "        input_ids, model_kwargs = self.model._expand_inputs_for_generation(\n",
    "            input_ids, expand_size=num_beams, is_encoder_decoder=True, **model_kwargs\n",
    "        )\n",
    "        \n",
    "        batch_size = len(beam_scorer._beam_hyps)\n",
    "        \n",
    "        batch_beam_size, cur_len = input_ids.shape\n",
    "        \n",
    "        beam_scores = torch.zeros((batch_size, num_beams), \n",
    "                                  dtype = torch.float, \n",
    "                                  device = self.device)\n",
    "        beam_scores[:, 1:] = -1e-9\n",
    "        beam_scores = beam_scores.view((batch_size * num_beams,))\n",
    "        beam_indices = (None)\n",
    "        \n",
    "        \n",
    "        \n",
    "        while True:            \n",
    "        \n",
    "            model_in = self.model.prepare_inputs_for_generation(input_ids, **model_kwargs)\n",
    "            outputs = self.model(**model_in, \n",
    "                                 return_dict=True,\n",
    "                                 output_attentions = False,\n",
    "                                 output_hidden_states = False)\n",
    "            \n",
    "            # Update togl_logits to zero selected terms in output\n",
    "            togl_probs[input_ids] = 0. #float('-inf')\n",
    "                        \n",
    "            # Modify logits\n",
    "            raw_logits = outputs.logits\n",
    "            if cur_len >= togl_start:\n",
    "                mod_logits = self.togl_func(raw_logits, togl_probs)\n",
    "            else:\n",
    "                mod_logits = raw_logits\n",
    "            mod_logits = mod_logits[:, -1, :]\n",
    "            \n",
    "            next_logits = self.model.model.adjust_logits_during_generation(mod_logits, cur_len = cur_len)\n",
    "            next_scores = F.log_softmax(next_logits, dim = -1)\n",
    "            \n",
    "            next_scores_pp = logits_processor(input_ids, next_scores)\n",
    "            next_scores = next_scores_pp + beam_scores[:, None].expand_as(next_scores)\n",
    "            \n",
    "            vocab_size  = next_scores.shape[-1]\n",
    "            next_scores = next_scores.view(batch_size, num_beams * vocab_size)\n",
    "            \n",
    "            next_scores, next_tokens = torch.topk(\n",
    "                next_scores, 2 * num_beams, dim = 1, largest = True, sorted = True\n",
    "            )\n",
    "            \n",
    "            next_idxs = torch_int_div(next_tokens, vocab_size)\n",
    "            next_tokens = next_tokens % vocab_size\n",
    "            \n",
    "            beam_outputs = beam_scorer.process(\n",
    "                input_ids,\n",
    "                next_scores,\n",
    "                next_tokens,\n",
    "                next_idxs,\n",
    "                pad_token_id=self.tokenizer.pad_token_id,\n",
    "                eos_token_id=self.tokenizer.eos_token_id,\n",
    "                beam_indices=beam_indices,\n",
    "            )\n",
    "            beam_scores = beam_outputs[\"next_beam_scores\"]\n",
    "            beam_next_tokens = beam_outputs[\"next_beam_tokens\"]\n",
    "            beam_idx = beam_outputs[\"next_beam_indices\"]\n",
    "            \n",
    "            input_ids = torch.cat([input_ids[beam_idx, :], beam_next_tokens.unsqueeze(-1)], dim = -1)\n",
    "            \n",
    "            model_kwargs = self.model.model._update_model_kwargs_for_generation(\n",
    "                outputs, model_kwargs, is_encoder_decoder = True\n",
    "            )\n",
    "            \n",
    "            cur_len += 1\n",
    "            \n",
    "            if beam_scorer.is_done or stopping_criteria(input_ids, None):\n",
    "                break\n",
    "            \n",
    "        seq_outputs = beam_scorer.finalize(\n",
    "            input_ids,\n",
    "            beam_scores,\n",
    "            next_tokens,\n",
    "            next_idxs,\n",
    "            pad_token_id = self.tokenizer.pad_token_id,\n",
    "            eos_token_id = self.tokenizer.eos_token_id,\n",
    "            max_length = stopping_criteria.max_length,\n",
    "            beam_indices = beam_indices,\n",
    "        )\n",
    "        \n",
    "        return seq_outputs['sequences']\n",
    "    \n",
    "    def togl_sum(self, raw_out, togl_probs):\n",
    "        norms = raw_out.norm(dim = -1)\n",
    "        togl_probs = togl_probs.unsqueeze(0).repeat((raw_out.shape[0], 1))\n",
    "        mod_logits = ((raw_out.squeeze()/norms) + togl_probs) * norms\n",
    "        mod_logits = mod_logits.unsqueeze(1)\n",
    "        return mod_logits\n",
    "    \n",
    "    def togl_convert(self, togl_tuple, togl_weight):\n",
    "        full_dist = torch.zeros((self.vocab_size), device = self.device)\n",
    "        probs = togl_tuple[0]\n",
    "        idxs  = togl_tuple[1]\n",
    "        full_dist[idxs] = probs\n",
    "        if full_dist.sum() > 0:\n",
    "            full_dist = (full_dist / full_dist.sum()) * togl_weight\n",
    "        \n",
    "        print(full_dist.sum())\n",
    "        \n",
    "        return full_dist\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18893067-5a73-42ee-91ba-3c87d7ff065d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = ['The top US hostage affairs official on Sunday reflected on conducting the prisoner swap that led to Brittney Griner’s release, saying the WNBA star immediately thanked the crew returning her to the United States.\\n“When she finally got on to the US plane, I said, ‘Brittney, you must have been through a lot over the last 10 months. Here’s your seat. Please feel free to decompress. We’ll give you your space,’” Special Presidential Envoy for Hostage Affairs Roger Carstens told CNN’s Dana Bash on “State of the Union.”\\n“And she said, ‘Oh no. I’ve been in prison for 10 months now listening to Russian, I want to talk. But first of all, who are these guys?’ And she moved right past me and went to every member on that crew, looked them in the eyes, shook their hands and asked about them and got their names, making a personal connection with them. It was really amazing,” Carstens recalled. “And then later on, on an 18 hour flight, she probably spent 12 hours just talking and we talked about everything under the sun.', 'goodbye my fellow compatriate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "464401c5-5b0d-404b-93c3-1976479bdfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_inputs = bart_tokenizer(inputs, padding = True, return_tensors = 'pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c794339-ac5b-4143-8fa7-4436599add76",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_inputs = tok_inputs.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5e9e4e57-0cfd-454f-bb61-ac747dba353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(tok_inputs['input_ids'], min_length = 10, max_length = 20, \n",
    "                        num_beams = 3, no_repeat_ngram_size = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eb618cdd-2a4e-4e0e-bffa-302c92a2bd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,     0, 14323,   382, 16301,  5185,   781,  7680,    15,     5,\n",
       "         16796, 12313,    14,   669,     7, 16278,  2596,  2974,  5101,     2],\n",
       "        [    2,     0,  8396, 33542,   127,  2598, 20840,  1069,   877,     4,\n",
       "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "beb6cfd5-47bc-4820-b30b-1bee27a954f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Top US hostage affairs official reflected on the prisoner swap that led to Brittney Griner'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart_tokenizer.decode(output[0], skip_special_tokens = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7de8a534-7a89-4eee-8a95-38f1fdb24376",
   "metadata": {},
   "outputs": [],
   "source": [
    "togl_dist = (\n",
    "    [0.0005 * i for i in range(15)],\n",
    "    [i + 5 for i in range(15)]\n",
    ")\n",
    "\n",
    "togl_dist = (torch.tensor(togl_dist[0]).to(device), torch.tensor(togl_dist[1]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ea1e86a9-cdb8-4af2-bcf4-b91a319c0856",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = ToGLDecoder(model, bart_tokenizer,\n",
    "                     device = device\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f57af7cb-bc5c-4baf-9bf6-3c9fce11c603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1000, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "output = decoder.generate(tok_inputs['input_ids'][0].unsqueeze(0), \n",
    "                          togl_dist, togl_start = 5,\n",
    "                          togl_weight = 0.1,\n",
    "                          min_length = 2, max_length = 64,\n",
    "                          no_repeat_ngram_size = 3,\n",
    "                          num_beams = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3043439b-d57b-4e27-b844-d0157a24d2db",
   "metadata": {},
   "source": [
    "Ġ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ab1a1311-58ab-40f5-b2b8-89c06ed8b37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../../../data/polisum_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "be770dfa-7485-4f03-9971-33716e6d17b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_url</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>left_sum</th>\n",
       "      <th>right_sum</th>\n",
       "      <th>linked_arts</th>\n",
       "      <th>left_op</th>\n",
       "      <th>right_op</th>\n",
       "      <th>linked_arts_clean</th>\n",
       "      <th>reddit_text</th>\n",
       "      <th>twitter_text</th>\n",
       "      <th>sm_text</th>\n",
       "      <th>num_reddit</th>\n",
       "      <th>num_twitter</th>\n",
       "      <th>num_sm</th>\n",
       "      <th>h1_text</th>\n",
       "      <th>h2_text</th>\n",
       "      <th>sm_text_primera</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https:/theflipside.io/archives/checks-in-the-mail</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>Checks In The Mail</td>\n",
       "      <td>The left supports cash payments and argues tha...</td>\n",
       "      <td>The right is generally supportive of helping c...</td>\n",
       "      <td>['https://www.politico.com/news/magazine/2020/...</td>\n",
       "      <td>One of the strangest spectacles in the economi...</td>\n",
       "      <td>Fiscal conservatives, like the Tea Partiers of...</td>\n",
       "      <td>['https://www.politico.com/news/magazine/2020/...</td>\n",
       "      <td>Is the U.S.|||Headed Toward a Short British-St...</td>\n",
       "      <td>With the bailout,  President Trump and Congres...</td>\n",
       "      <td>Adam Brandon: $1 trillion coronavirus economic...</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>69</td>\n",
       "      <td>Republicans would have screamed bloody murder ...</td>\n",
       "      <td>Headed Toward a Short British-Style Election?|...</td>\n",
       "      <td>Adam Brandon: $1 trillion coronavirus economic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https:/theflipside.io/archives/eos-regarding-t...</td>\n",
       "      <td>2021-01-26</td>\n",
       "      <td>EOs Regarding Transgender Rights</td>\n",
       "      <td>The left is supportive of both policies.</td>\n",
       "      <td>The right is critical of both policies.</td>\n",
       "      <td>['https://www.spectator.co.uk/article/biden-s-...</td>\n",
       "      <td>[The Trump administration] tried to argue in c...</td>\n",
       "      <td>The existing policy—that of former President D...</td>\n",
       "      <td>['https://www.spectator.co.uk/article/biden-s-...</td>\n",
       "      <td>Missouri state lawmaker charged with selling f...</td>\n",
       "      <td>By me for @SpecCoffeeHouse: \"boys who identify...</td>\n",
       "      <td>“ This year, state lawmakers also want to rest...</td>\n",
       "      <td>15</td>\n",
       "      <td>76</td>\n",
       "      <td>91</td>\n",
       "      <td>Trump resigns from Screen Actors Guild in rant...</td>\n",
       "      <td>Trans people can serve openly in the US milita...</td>\n",
       "      <td>“ This year, state lawmakers also want to rest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https:/theflipside.io/archives/facebook-and-br...</td>\n",
       "      <td>2019-04-02</td>\n",
       "      <td>Facebook and Breaking Up Big Tech</td>\n",
       "      <td>The left is skeptical of Zuckerberg’s motives,...</td>\n",
       "      <td>The right is disturbed by the free speech impl...</td>\n",
       "      <td>['https://medium.com/@teamwarren/heres-how-we-...</td>\n",
       "      <td>All of this might sound reasonable on its face...</td>\n",
       "      <td>Facebook's nominal raison d'etre is to serve a...</td>\n",
       "      <td>['https://medium.com/@teamwarren/heres-how-we-...</td>\n",
       "      <td>Fox news calls out Trump lie about Wikileaks||...</td>\n",
       "      <td>Remember when people criticized @ewarren for s...</td>\n",
       "      <td>Corporate self-governance has failed in part b...</td>\n",
       "      <td>12</td>\n",
       "      <td>79</td>\n",
       "      <td>91</td>\n",
       "      <td>UN experts warn Assange arrest exposes him to ...</td>\n",
       "      <td>Do you see the fall of Fakebook?|||#facebook #...</td>\n",
       "      <td>Corporate self-governance has failed in part b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https:/theflipside.io/archives/general-electio...</td>\n",
       "      <td>2020-10-28</td>\n",
       "      <td>General Election Update</td>\n",
       "      <td>The left is optimistic about Biden’s chances.</td>\n",
       "      <td>The right is cautiously optimistic about Trump...</td>\n",
       "      <td>['https://theflipside.us15.list-manage.com/tra...</td>\n",
       "      <td>Right now, Joe Biden is vastly outspending Don...</td>\n",
       "      <td>At this point, you should be saying something ...</td>\n",
       "      <td>['https://projects.fivethirtyeight.com/trump-b...</td>\n",
       "      <td>Text: Joe Biden, on verge of victory says, ‘We...</td>\n",
       "      <td>It's morning, and like we expected we still do...</td>\n",
       "      <td>“The mistake the Clinton campaign made in Mich...</td>\n",
       "      <td>20</td>\n",
       "      <td>59</td>\n",
       "      <td>79</td>\n",
       "      <td>While Nate makes the case in here no Biden isn...</td>\n",
       "      <td>&lt;URL&gt;|||&lt;URL&gt;|||Pennsylvanians -- history has ...</td>\n",
       "      <td>“The mistake the Clinton campaign made in Mich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https:/theflipside.io/archives/impeachment-hea...</td>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>Impeachment Hearings Continue</td>\n",
       "      <td>The left supports impeachment, arguing that th...</td>\n",
       "      <td>The right opposes impeachment, arguing that th...</td>\n",
       "      <td>['https://theflipside.us15.list-manage.com/tra...</td>\n",
       "      <td>‘Everyone was in the loop. It was no secret.’ ...</td>\n",
       "      <td>Polls show the vast majority of Americans agre...</td>\n",
       "      <td>['https://nypost.com/2019/11/21/fiona-hill-and...</td>\n",
       "      <td>Trade talks should also be climate talks|||Tru...</td>\n",
       "      <td>Fiona Hill (and Dems) ignore the serious evide...</td>\n",
       "      <td>&lt;UNAME&gt; &lt;UNAME&gt; &lt;UNAME&gt; &lt;UNAME&gt; &lt;UNAME&gt; Can so...</td>\n",
       "      <td>18</td>\n",
       "      <td>68</td>\n",
       "      <td>86</td>\n",
       "      <td>Banker who signed off Trump loans found dead a...</td>\n",
       "      <td>&lt;URL&gt;|||\"And in 2018 House testimony, Nellie O...</td>\n",
       "      <td>&lt;UNAME&gt; &lt;UNAME&gt; &lt;UNAME&gt; &lt;UNAME&gt; &lt;UNAME&gt; Can so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         article_url        date  \\\n",
       "0  https:/theflipside.io/archives/checks-in-the-mail  2020-03-20   \n",
       "1  https:/theflipside.io/archives/eos-regarding-t...  2021-01-26   \n",
       "2  https:/theflipside.io/archives/facebook-and-br...  2019-04-02   \n",
       "3  https:/theflipside.io/archives/general-electio...  2020-10-28   \n",
       "4  https:/theflipside.io/archives/impeachment-hea...  2019-11-22   \n",
       "\n",
       "                               title  \\\n",
       "0                 Checks In The Mail   \n",
       "1   EOs Regarding Transgender Rights   \n",
       "2  Facebook and Breaking Up Big Tech   \n",
       "3            General Election Update   \n",
       "4      Impeachment Hearings Continue   \n",
       "\n",
       "                                            left_sum  \\\n",
       "0  The left supports cash payments and argues tha...   \n",
       "1           The left is supportive of both policies.   \n",
       "2  The left is skeptical of Zuckerberg’s motives,...   \n",
       "3      The left is optimistic about Biden’s chances.   \n",
       "4  The left supports impeachment, arguing that th...   \n",
       "\n",
       "                                           right_sum  \\\n",
       "0  The right is generally supportive of helping c...   \n",
       "1            The right is critical of both policies.   \n",
       "2  The right is disturbed by the free speech impl...   \n",
       "3  The right is cautiously optimistic about Trump...   \n",
       "4  The right opposes impeachment, arguing that th...   \n",
       "\n",
       "                                         linked_arts  \\\n",
       "0  ['https://www.politico.com/news/magazine/2020/...   \n",
       "1  ['https://www.spectator.co.uk/article/biden-s-...   \n",
       "2  ['https://medium.com/@teamwarren/heres-how-we-...   \n",
       "3  ['https://theflipside.us15.list-manage.com/tra...   \n",
       "4  ['https://theflipside.us15.list-manage.com/tra...   \n",
       "\n",
       "                                             left_op  \\\n",
       "0  One of the strangest spectacles in the economi...   \n",
       "1  [The Trump administration] tried to argue in c...   \n",
       "2  All of this might sound reasonable on its face...   \n",
       "3  Right now, Joe Biden is vastly outspending Don...   \n",
       "4  ‘Everyone was in the loop. It was no secret.’ ...   \n",
       "\n",
       "                                            right_op  \\\n",
       "0  Fiscal conservatives, like the Tea Partiers of...   \n",
       "1  The existing policy—that of former President D...   \n",
       "2  Facebook's nominal raison d'etre is to serve a...   \n",
       "3  At this point, you should be saying something ...   \n",
       "4  Polls show the vast majority of Americans agre...   \n",
       "\n",
       "                                   linked_arts_clean  \\\n",
       "0  ['https://www.politico.com/news/magazine/2020/...   \n",
       "1  ['https://www.spectator.co.uk/article/biden-s-...   \n",
       "2  ['https://medium.com/@teamwarren/heres-how-we-...   \n",
       "3  ['https://projects.fivethirtyeight.com/trump-b...   \n",
       "4  ['https://nypost.com/2019/11/21/fiona-hill-and...   \n",
       "\n",
       "                                         reddit_text  \\\n",
       "0  Is the U.S.|||Headed Toward a Short British-St...   \n",
       "1  Missouri state lawmaker charged with selling f...   \n",
       "2  Fox news calls out Trump lie about Wikileaks||...   \n",
       "3  Text: Joe Biden, on verge of victory says, ‘We...   \n",
       "4  Trade talks should also be climate talks|||Tru...   \n",
       "\n",
       "                                        twitter_text  \\\n",
       "0  With the bailout,  President Trump and Congres...   \n",
       "1  By me for @SpecCoffeeHouse: \"boys who identify...   \n",
       "2  Remember when people criticized @ewarren for s...   \n",
       "3  It's morning, and like we expected we still do...   \n",
       "4  Fiona Hill (and Dems) ignore the serious evide...   \n",
       "\n",
       "                                             sm_text  num_reddit  num_twitter  \\\n",
       "0  Adam Brandon: $1 trillion coronavirus economic...          15           54   \n",
       "1  “ This year, state lawmakers also want to rest...          15           76   \n",
       "2  Corporate self-governance has failed in part b...          12           79   \n",
       "3  “The mistake the Clinton campaign made in Mich...          20           59   \n",
       "4  <UNAME> <UNAME> <UNAME> <UNAME> <UNAME> Can so...          18           68   \n",
       "\n",
       "   num_sm                                            h1_text  \\\n",
       "0      69  Republicans would have screamed bloody murder ...   \n",
       "1      91  Trump resigns from Screen Actors Guild in rant...   \n",
       "2      91  UN experts warn Assange arrest exposes him to ...   \n",
       "3      79  While Nate makes the case in here no Biden isn...   \n",
       "4      86  Banker who signed off Trump loans found dead a...   \n",
       "\n",
       "                                             h2_text  \\\n",
       "0  Headed Toward a Short British-Style Election?|...   \n",
       "1  Trans people can serve openly in the US milita...   \n",
       "2  Do you see the fall of Fakebook?|||#facebook #...   \n",
       "3  <URL>|||<URL>|||Pennsylvanians -- history has ...   \n",
       "4  <URL>|||\"And in 2018 House testimony, Nellie O...   \n",
       "\n",
       "                                     sm_text_primera  \n",
       "0  Adam Brandon: $1 trillion coronavirus economic...  \n",
       "1  “ This year, state lawmakers also want to rest...  \n",
       "2  Corporate self-governance has failed in part b...  \n",
       "3  “The mistake the Clinton campaign made in Mich...  \n",
       "4  <UNAME> <UNAME> <UNAME> <UNAME> <UNAME> Can so...  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b524a5bb-11f7-465d-84b3-1efed8b05f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
