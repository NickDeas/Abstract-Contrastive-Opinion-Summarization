{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "186037d3-9e6b-407d-bafe-a5d47be60a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO, TraceMeanField_ELBO\n",
    "from pyro.optim import Adam, ClippedAdam\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import MultiheadAttention, TransformerEncoderLayer, TransformerEncoder, Linear, Dropout, LayerNorm\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import handle_torch_function, has_torch_function\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from treelib import Node, Tree\n",
    "# import igraph\n",
    "# from igraph import Graph, EdgeSeq\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "from typing import Optional, List, Union, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import plotly.graph_objects as go\n",
    "\n",
    "import math\n",
    "\n",
    "import copy as copy\n",
    "\n",
    "from graphviz import Source, Digraph\n",
    "from IPython.core.display import SVG\n",
    "\n",
    "import data_read, data_utils, dataset, model_utils, topic_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd3083e2-7bf9-4658-afa0-be88ffafdc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/proj/nlp/users/ndeas/acos/data/'\n",
    "BASE_DIR = '/home/ndeas/abstract_cos/Abstract-Contrastive-Opinion-Summarization/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4aba14-070e-494f-b29b-cf1a4b097282",
   "metadata": {},
   "source": [
    "# Data Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e01863e-81e9-496c-a996-59285f96af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "UP_SOURCE = BASE_DIR + 'polisumm_eval_short.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b937616b-92a5-4d7b-b773-e0873056e97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(UP_SOURCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e0cf9a6-862a-42fe-930c-496cf13b071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['split_texts'] = data['all_texts'].str.split('|')\n",
    "data['num_src'] = data['split_texts'].apply(len)\n",
    "data['repeat_title'] = data.apply(lambda row: [row['title'] for _ in range(row['num_src'])], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e59223b3-dbc5-409d-a429-54db5271f637",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_texts = [src for slist in data['split_texts'].values for src in slist]\n",
    "titles = [t for tlist in data['repeat_title'].values for t in tlist]\n",
    "topic_df = pd.DataFrame({'text': split_texts, 'title': titles})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c1dd9c8-baea-4690-a3ad-a57ff937b58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df.to_csv(DATA_DIR + 'polisumm_tam_src.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f365df44-c31a-4104-a3db-0b95d935599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "UP_SOURCE = DATA_DIR + 'polisumm_tam_src.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad3c130-fe68-461d-a2b3-7ca1824264df",
   "metadata": {},
   "source": [
    "## Pre Processing and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90ea89ba-2538-42fb-ac1a-aacf1345509c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from /proj/nlp/users/ndeas/acos/data/polisumm_tam_src.csv\n",
      "Cleaning text data \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 125873/125873 [00:59<00:00, 2115.95it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████| 35964/35964 [00:17<00:00, 2012.03it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████| 17983/17983 [00:08<00:00, 2111.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting vectorizer\n",
      "Vectorizer trained with vocab size 10000\n",
      "Filtering documents with less than 2 tokens\n",
      "Saving data to /proj/nlp/users/ndeas/acos/data/polisumm_tam_val.csv/['train', 'test', 'val'].csv\n",
      "/proj/nlp/users/ndeas/acos/data/polisumm_tam_val.csv does not exist, creating directory.\n",
      "Saved all data, vectorizer, and author mapping to /proj/nlp/users/ndeas/acos/data/polisumm_tam_val.csv\n"
     ]
    }
   ],
   "source": [
    "OUTPUT = DATA_DIR + 'polisumm_tam_val.csv'\n",
    "data_utils.read_and_process_data(UP_SOURCE, OUTPUT,\n",
    "                                 test_frac = 0.2, val_frac = 0.1,\n",
    "                                 max_vocab = 10000,\n",
    "                                 ext_verbs = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2b77a07-7e11-426f-8b1d-5261c381a786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from /proj/nlp/users/ndeas/acos/data/polisumm_tam_src.csv\n",
      "Cleaning text data \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 179820/179820 [01:18<00:00, 2289.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting vectorizer\n",
      "Vectorizer trained with vocab size 10000\n",
      "Filtering documents with less than 2 tokens\n",
      "Saving data to /proj/nlp/users/ndeas/acos/data/polisumm_tam_prod.csv/['train'].csv\n",
      "/proj/nlp/users/ndeas/acos/data/polisumm_tam_prod.csv does not exist, creating directory.\n",
      "Saved all data, vectorizer, and author mapping to /proj/nlp/users/ndeas/acos/data/polisumm_tam_prod.csv\n"
     ]
    }
   ],
   "source": [
    "OUTPUT = DATA_DIR + 'polisumm_tam_prod.csv'\n",
    "data_utils.read_and_process_data(UP_SOURCE, OUTPUT,\n",
    "                                 test_frac = 0, val_frac = 0,\n",
    "                                 max_vocab = 10000,\n",
    "                                 ext_verbs = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1454de-62a3-4499-a29d-99eed47116b8",
   "metadata": {},
   "source": [
    "# Model Definition "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5344c5-8946-4552-8b03-80d15ceedd0d",
   "metadata": {},
   "source": [
    "## Layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "012f77ff-c07c-42e4-8b1b-25c7625591ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "        Base class for the document encoder used within the guide\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, num_topics, hidden, dropout, encode_len: str = None, init_exp_len_root: float = None):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_size  = vocab_size\n",
    "        self.num_topics  = num_topics\n",
    "        self.hidden_size = hidden\n",
    "        self.dropout     = dropout\n",
    "        \n",
    "        self.drop = nn.Dropout(dropout)  # to avoid component collapse\n",
    "        self.fc1 = nn.Linear(vocab_size, hidden)\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden, hidden)\n",
    "            \n",
    "        self.fcmu = nn.Linear(hidden, num_topics)\n",
    "            \n",
    "        self.fclv = nn.Linear(hidden, num_topics)\n",
    "            \n",
    "        # NB: here we set `affine=False` to reduce the number of learning parameters\n",
    "        # See https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html\n",
    "        # for the effect of this flag in BatchNorm1d\n",
    "        self.bnmu = nn.BatchNorm1d(num_topics, affine=False)  # to avoid component collapse\n",
    "        self.bnlv = nn.BatchNorm1d(num_topics, affine=False)  # to avoid component collapse\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        h = F.softplus(self.fc1(inputs))\n",
    "        \n",
    "        if self.encode_len == 'hidden_deep':\n",
    "            len_tens = inputs.sum(-1)[:, None]\n",
    "            h = torch.concat((h, len_tens), axis = -1)  \n",
    "        h = F.softplus(self.fc2(h))\n",
    "        \n",
    "        h = self.drop(h)\n",
    "        \n",
    "        # μ and Σ are the outputs\n",
    "        logtheta_loc = self.bnmu(self.fcmu(h))\n",
    "            \n",
    "        logtheta_logvar = self.bnlv(self.fclv(h))\n",
    "        logtheta_scale = 1.0e-10 + (0.5 * logtheta_logvar).exp()  # Defenisvely enforces positivity\n",
    "            \n",
    "        return logtheta_loc, logtheta_scale\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca0e63d0-840f-47c2-be71-ef90c6b707b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AspEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "        Base class for the document encoder used within the guide\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, num_aspects, hidden, dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_size  = vocab_size\n",
    "        self.num_topics  = num_topics\n",
    "        self.hidden_size = hidden\n",
    "        self.dropout     = dropout\n",
    "        \n",
    "        self.drop = nn.Dropout(dropout)  # to avoid component collapse\n",
    "        self.fc1 = nn.Linear(vocab_size, hidden)\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden, hidden)\n",
    "            \n",
    "        self.fcmu = nn.Linear(hidden, num_aspects)\n",
    "            \n",
    "        self.fclv = nn.Linear(hidden, num_aspects)\n",
    "            \n",
    "        self.bnmu = nn.BatchNorm1d(num_aspects, affine=False)  # to avoid component collapse\n",
    "        self.bnlv = nn.BatchNorm1d(num_aspects, affine=False)  # to avoid component collapse\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        h = F.softplus(self.fc1(inputs))  \n",
    "        h = F.softplus(self.fc2(h))\n",
    "        \n",
    "        h = self.drop(h)\n",
    "        \n",
    "        # μ and Σ are the outputs\n",
    "        logtheta_loc = self.bnmu(self.fcmu(h))\n",
    "            \n",
    "        logtheta_logvar = self.bnlv(self.fclv(h))\n",
    "        logtheta_scale = 1.0e-10 + (0.5 * logtheta_logvar).exp()  # Defenisvely enforces positivity\n",
    "            \n",
    "        return logtheta_loc, logtheta_scale\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c52fc057-6f6e-4194-a0d8-737e0286ec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "        Base class for the document decoder used in the model\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, num_topics, dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_size  = vocab_size\n",
    "        self.num_topics  = num_topics\n",
    "        self.dropout     = dropout\n",
    "        \n",
    "        self.beta = nn.Linear(num_topics, vocab_size, bias=False)\n",
    "        self.bn = nn.BatchNorm1d(vocab_size, affine=False)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = self.drop(inputs)\n",
    "        # the output is σ(βθ)\n",
    "        return self.bn(self.beta(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767ecb87-2c20-4131-a428-eebcba6e74f6",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e06c074-3917-46de-b5e2-3a835ad91d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TAM(nn.Module):\n",
    "    def __init__(self, num_topics:int, num_aspects: int\n",
    "                 hidden_size: int = None,\n",
    "                 vocab_size: int = None,\n",
    "                 dropout: float = None,\n",
    "                 encoder: Encoder = None, decoder: Decoder = None, \n",
    "                 encode_len: str = None, len_pow_val: float = None,\n",
    "                 delta_prior: pyro.distributions.torch_distribution.TorchDistributionMixin = None,\n",
    "                 delta_scale: int = 3,\n",
    "                 device: torch.device = None):\n",
    "        \"\"\"\n",
    "            ProdLDA implementation including model and guide.\n",
    "            \n",
    "            Parameters:\n",
    "                num_topics: int\n",
    "                    Number of latent topics assumed\n",
    "                hidden_size: int (optional)\n",
    "                    Size of the hidden layer in the Encoder\n",
    "                vocab_size: int (optional)\n",
    "                    Number of tokens in the vocabulary\n",
    "                dropout: float (optional)\n",
    "                    Dropout rate for the encoder\n",
    "                encoder: models.layers.Encoder (optional)\n",
    "                    Encoder layer(s) transforming document BOW's into a topic distribution\n",
    "                decoder: models.layers.Decoder (optional)\n",
    "                    Decoder layer(s) transforming topic distribution into a document BOW.\n",
    "                    Essentially describes the Beta matrix num_topics x vocab_size\n",
    "                delta_prior: pyro.distributions (optional)\n",
    "                    Prior distribution on the latent topics\n",
    "                device: torch.device (optional)\n",
    "                    GPU/CPU device to use in training/inference\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()   \n",
    "        \n",
    "        self.num_topics = num_topics\n",
    "        self.num_aspects = num_aspects\n",
    "        \n",
    "        if not ((hidden_size and vocab_size and dropout) or encoder):\n",
    "            raise Exception('Either hidden_size, vocab_size, and dropout or an encoder must be specified.')\n",
    "        if not ((vocab_size and dropout) or decoder):\n",
    "            raise Exception('Either vocab_size or a decoder must be specified')\n",
    "                \n",
    "        self.hidden_size = hidden_size if hidden_size else encoder.hidden_size\n",
    "        self.vocab_size  = vocab_size if vocab_size else encoder.vocab_size\n",
    "        self.dropout     = dropout if dropout else encoder.dropout\n",
    "        \n",
    "        self.encode_len = encode_len\n",
    "        \n",
    "        self.encoder  = encoder if encoder else Encoder(vocab_size, num_topics, hidden_size, dropout, encode_len = encode_len, len_pow_val = len_pow_val)\n",
    "        self.decoder = decoder if decoder else Decoder(vocab_size, num_topics, dropout)\n",
    "        \n",
    "        self.device = device if device else torch.device(\"cpu\")\n",
    "        self.to(self.device)\n",
    "        \n",
    "        self.delta_prior = delta_prior if delta_prior else dist.Normal(0, delta_scale * torch.ones(num_topics, device=self.device))\n",
    "\n",
    "    def model(self,\n",
    "              bows: torch.Tensor, \n",
    "              num_docs: int, \n",
    "              h2: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "            The ProdLDA model to generate a corpus of documents\n",
    "            \n",
    "            Parameters:\n",
    "                bows: torch.Tensor\n",
    "                    The corpus of source document BOWS for loss calculations\n",
    "                num_docs: int\n",
    "                    The total number of documents in the source corpus\n",
    "                h2: torch.Tensor (optional, default = None)\n",
    "                    If half (either ordered or random) of the document texts are passed for\n",
    "                        bows, then the remaining half should be passed as h2\n",
    "        \"\"\"\n",
    "        \n",
    "        pyro.module(\"decoder\", self.decoder)\n",
    "                \n",
    "        with pyro.plate(\"documents\", num_docs, subsample = bows):\n",
    "            delta = pyro.sample(\"delta\", self.delta_prior.to_event(1))\n",
    "\n",
    "            # Softmax to calculate theta, the distribution over topics: (Docs, Topics)\n",
    "            theta = F.softmax(delta, -1)\n",
    "\n",
    "            # Decode the topic distribution to generate distribution over words: (Docs, Vocab Size)\n",
    "            logits = self.decoder(theta)\n",
    "\n",
    "            # Maximum document length for multinomial distribution sampling of reconstruction\n",
    "            total_count = int((bows if h2 is None else h2).sum(-1).max()) \n",
    "\n",
    "            # Sample document reconstruction from multinomial characterized by decoded topic distribution\n",
    "            pyro.sample(\n",
    "                'words',\n",
    "                dist.Multinomial(total_count, logits = logits),\n",
    "                obs=bows if h2 is None else h2\n",
    "            )\n",
    "\n",
    "    def guide(self, \n",
    "              bows: torch.Tensor, \n",
    "              num_docs: int, \n",
    "              h2: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "            The ProdLDA guide for learning latent variables\n",
    "            \n",
    "            Parameters:\n",
    "                bows: torch.Tensor\n",
    "                    The corpus of source document BOWS for loss calculations\n",
    "                num_docs: int\n",
    "                    The total number of documents in the source corpus\n",
    "                h2: torch.Tensor (optional, default = None)\n",
    "                    If half (either ordered or random) of the document texts are passed for\n",
    "                        bows, then the remaining half should be passed as h2\n",
    "        \"\"\"\n",
    "        \n",
    "        pyro.module('encoder', self.encoder)\n",
    "\n",
    "        # document plate\n",
    "        with pyro.plate(\"documents\", num_docs, subsample = bows):\n",
    "\n",
    "            delta_loc, delta_sigma = self.encoder(bows.float())\n",
    "\n",
    "            pyro.sample(f\"delta\", dist.Normal(delta_loc, delta_sigma).to_event(1))\n",
    "\n",
    "    def beta(self):\n",
    "        # beta matrix elements are the weights of the FC layer on the decoder\n",
    "        return self.decoder.beta.weight.detach().T\n",
    "    \n",
    "    def get_doc_scale(self, bows):\n",
    "        _, delta_sigma = self.encoder(bows.float())\n",
    "        \n",
    "        return delta_sigma\n",
    "    \n",
    "    def reconstruct_doc(self, bow, num_particles = 50):\n",
    "        self.eval()\n",
    "\n",
    "        num_docs = bow.shape[0]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            delta_loc, delta_scale = self.encoder(bow)  \n",
    "\n",
    "        delta_samples = dist.Normal(delta_loc, delta_scale).sample((num_particles,))\n",
    "\n",
    "        theta = F.softmax(delta_samples, dim=-1)\n",
    "\n",
    "        # decode for reconstruction\n",
    "        with torch.no_grad():\n",
    "            theta = theta.view(num_docs*num_particles, -1)\n",
    "            word_logits = self.decoder(theta)\n",
    "            word_logits = word_logits.view(num_particles, num_docs, -1)\n",
    "\n",
    "        word_probs = torch.softmax(word_logits, axis=-1).mean(axis=0)\n",
    "\n",
    "        return word_probs\n",
    "    \n",
    "    def calc_perplexity(self, test_half_loader, num_particles = 50, output_indiv = False):\n",
    "        \"\"\"\n",
    "        Calculate perplexity\n",
    "        \"\"\"\n",
    "\n",
    "        # Accumulated perplexity\n",
    "        total_ce = 0\n",
    "        total_num_words = 0\n",
    "        \n",
    "        if output_indiv:\n",
    "            lengths = []\n",
    "            perps   = []\n",
    "\n",
    "        for i, batch in enumerate(test_half_loader):   \n",
    "            bow = batch['bow'].to(self.device)\n",
    "\n",
    "            bow_recon = self.reconstruct_doc(bow, num_particles = num_particles)\n",
    "            ces       = (-bow*torch.log(bow_recon))\n",
    "            total_ce += ces.sum().cpu().item()\n",
    "            total_num_words += bow.sum()\n",
    "\n",
    "            if output_indiv:\n",
    "                new_lens = list(bow.sum(axis = -1).cpu().detach())\n",
    "                new_perps = list(torch.exp(ces).sum(-1).cpu().detach())\n",
    "                \n",
    "                lengths += new_lens\n",
    "                perps   += new_perps\n",
    "            \n",
    "        ce = total_ce / total_num_words\n",
    "        perp = torch.exp(ce)\n",
    "\n",
    "        if output_indiv:\n",
    "            return perp, ce, lengths, perps\n",
    "        else:\n",
    "            return perp, ce\n",
    "    \n",
    "    def doc_completion_perplexity(self, test_half_loader, num_particles = 50, output_indiv = False):\n",
    "        \"\"\"\n",
    "        Calculate document completion perplexity\n",
    "        \"\"\"\n",
    "\n",
    "        # Accumulated perplexity\n",
    "        total_ce = 0\n",
    "        total_num_words = 0\n",
    "        \n",
    "        if output_indiv:\n",
    "            lengths = []\n",
    "            perps   = []\n",
    "\n",
    "        for i, batch in enumerate(test_half_loader):   \n",
    "            h1  = batch['bow_h1'].to(self.device)\n",
    "            h2  = batch['bow_h2'].to(self.device)\n",
    "            ids = batch['author_id']\n",
    "            \n",
    "            h2_recon = self.reconstruct_doc(h1, num_particles = num_particles)\n",
    "            ces      = (-h2*torch.log(h2_recon))\n",
    "            total_ce += ces.sum().cpu().item()\n",
    "            total_num_words += h2.sum()\n",
    "            \n",
    "            if output_indiv:\n",
    "                new_lens = list((h1+h2).sum(axis = -1).cpu().detach())\n",
    "                new_perps = list(torch.exp(ces).sum(-1).cpu().detach())\n",
    "                \n",
    "                lengths += new_lens\n",
    "                perps   += new_perps\n",
    "\n",
    "        ce = total_ce / total_num_words\n",
    "        perp = torch.exp(ce)\n",
    "        \n",
    "        if output_indiv:\n",
    "            return perp, ce, lengths, perps\n",
    "        else:\n",
    "            return perp, ce\n",
    "    \n",
    "    def save(self, save_path:str):\n",
    "        \n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        \n",
    "        torch.save(self.encoder.state_dict(), f'{save_path}/encoder.pt')\n",
    "        torch.save(self.decoder.state_dict(), f'{save_path}/decoder.pt')\n",
    "        \n",
    "        with open(f'{save_path}/delta_prior.pkl', 'wb') as f:\n",
    "            pkl.dump(self.delta_prior, f)\n",
    "            \n",
    "            \n",
    "        config_dict = {\n",
    "            'model_type': 'prodlda',\n",
    "            'num_topics': self.num_topics,\n",
    "            'hidden_size': self.hidden_size,\n",
    "            'vocab_size': self.vocab_size,\n",
    "            'dropout': self.dropout,\n",
    "            'encode_len': self.encode_len,\n",
    "            'len_pow_val': self.encoder.len_pow.data.item(),\n",
    "        }\n",
    "        \n",
    "        with open(f'{save_path}/config.json', 'w') as f:\n",
    "            json.dump(config_dict, f)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_path, device = None):\n",
    "        \n",
    "        with open(f'{model_path}/config.json', 'r') as f:\n",
    "            config_dict = json.load(f)\n",
    "        \n",
    "        if config_dict['model_type'] != 'prodlda':\n",
    "            raise Exception(f'Pretrained model of type {config_dict[\"model_type\"]} is not of type ProdLDA')\n",
    "        \n",
    "        num_topics = config_dict['num_topics']\n",
    "        encode_len = config_dict['encode_len'] if 'encode_len' in config_dict.keys() else None\n",
    "        \n",
    "        encoder = Encoder(config_dict['vocab_size'],\n",
    "                         config_dict['num_topics'],\n",
    "                         config_dict['hidden_size'],\n",
    "                         config_dict['dropout'],\n",
    "                         encode_len = encode_len,\n",
    "                         len_pow_val = len_pow_val)\n",
    "        \n",
    "        decoder = Decoder(config_dict['vocab_size'],\n",
    "                         config_dict['num_topics'],\n",
    "                         config_dict['dropout'])\n",
    "        \n",
    "        encoder.load_state_dict(torch.load(f'{model_path}/encoder.pt'))\n",
    "        decoder.load_state_dict(torch.load(f'{model_path}/decoder.pt'))\n",
    "        \n",
    "        with open(f'{model_path}/delta_prior.pkl', 'rb') as f:\n",
    "            delta_prior = pkl.load(f)\n",
    "                        \n",
    "        model = cls(num_topics, \n",
    "                    encoder = encoder, decoder = decoder, \n",
    "                    delta_prior = delta_prior,\n",
    "                    encode_len = encode_len, len_pow_val = len_pow_val,\n",
    "                    device = device)\n",
    "        \n",
    "        return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
